{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procesamiento del habla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Speech filter model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T00:49:21.479923Z",
     "start_time": "2018-08-06T00:49:21.352719Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![speech_filter_model](speech_filter_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cepstrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$s(n) = x(n)*h(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$S(\\omega)=X(\\omega).H(\\omega)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$|S(\\omega)|=|X(\\omega)|.|H(\\omega)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\log|S(\\omega)|=\\log|X(\\omega)|+\\log|H(\\omega)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![Cepstrum](cepstrum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![Mel](mel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:12:51.269304Z",
     "start_time": "2018-08-05T16:12:51.255743Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Etiquetar a los MFCC con el fonema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:16:56.390431Z",
     "start_time": "2018-08-05T16:16:56.378471Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Set de entrenamiento: $x_1,...,x_N$ __y__ las etiquetas $z_1,...,z_N \\in 1,...,K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Maximum likelihood: \n",
    "\n",
    "$\\mu_k=$\n",
    "\n",
    "$\\sigma_k^2=$\n",
    "\n",
    "2. Obtener $k$ que maximice $P(k|x) = \\frac{P(x|k)P(k)}{P(x)} \\Rightarrow P(x|k)P(k)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aprendizaje NO supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:16:56.390431Z",
     "start_time": "2018-08-05T16:16:56.378471Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Set de entrenamiento: $x_1,...,x_N$ __sin__ las etiquetas $z_1,...,z_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algoritmo EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Asigna una probabilidad a cada $x$ de pertenecer a cada clase $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:24:25.496342Z",
     "start_time": "2018-08-05T16:24:25.484134Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1) __Inicializar__ $\\mu_k$, $\\sigma_k^2$, y $\\pi_k=P(k)$ para cada clase (p.ej.: K-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:27:33.157516Z",
     "start_time": "2018-08-05T16:27:33.143038Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) __Paso E__: Calcular $\\gamma_k(x) = P(z=k|x)$: probabilidad de que la muestra $x$ pertenezca a la clase $k$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3) __Paso M__: Reestimar $\\mu_k$, $\\sigma_k^2$, y $\\pi_k=P(k)$ para cada clase.\n",
    "\n",
    "$$\\mu_k=\\frac{\\sum_{i=1}^N \\gamma_k(x_i) x_i}{\\sum_{i=1}^N \\gamma_k(x_i)}$$\n",
    "\n",
    "$$\\sigma_k^2=\\frac{\\sum_{i=1}^N \\gamma_k(x_i) (x_i-\\mu_k)^2}{\\sum_{i=1}^N \\gamma_k(x_i)}$$\n",
    "\n",
    "$$\\pi_k=\\frac{1}{N}\\sum_{i=1}^N \\gamma_k(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4) Calcular __log-likelihood__\n",
    "\n",
    "$$P(x_i) = \\sum_{k=1}^K \\pi_k \\mathcal{N} (x_i|\\mu_k,\\sigma_k^2)$$\n",
    "\n",
    "$$LL = \\log \\prod_{i=1}^N P(x_i) = \\sum_{i=1}^N \\log P(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "5) Repetir 2, 3, 4 hasta que el log-likelihood no cambie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Estados\n",
    "- Transiciones: probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Experimento: generar secuencia de estados $Q=q_1,...,q_T$\n",
    "\n",
    "* $P(qt|q_{t-1},q_{t-2},...q_1) = P(q_t|q_{t-1})$ : la probabilidad de pasar de un estado a otro NO DEPENDE de todo la secuencia de estados previa\n",
    "* $a_{ij} = P(q_t=j|q_{t-1}=i)$: la probabilidad de pasar de un estado a otro es constante en el tiempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov Ocultas (HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- En cada estado se genera una observación $\\Rightarrow$ distribución de probabilidad\n",
    "- $Q = q_1,q_2,...q_T$ : secuencia de estados\n",
    "- $Y = y_1,y_2,...,y_T$ : secuencia de observaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T17:08:14.205125Z",
     "start_time": "2018-08-05T17:08:14.186550Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(y_t|Q,Y_{-t}) = P(y_t|q_t=j)$: la observación generada en un estado sólo depende de cuál es el estado actual $\\Rightarrow P(y_t|q_t=j)=b_j(y_t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Modelo: $\\lambda=\\{\\{i\\},\\{a_{ij}\\},\\{b_j(y_t)\\}\\}$, con $i,j = 1,...,N$, $t = 1,...,T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo de Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Dado $\\lambda$ y una secuencia de observaciones $Y=y_1,...,y_T$, hallar la secuencia de estados óptima $Q^*=q_1^*,...,q_T^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\DeclareMathOperator*{\\argmax}{argmax}$\n",
    "$Q^*=\\argmax\\limits_{\\forall \\ Q} P(Q|Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\phi_t(j)=\\max\\limits_{\\forall \\ Q_{t-1}} P(Q_{t-1},q_t=j,Y_t)$: probabilidad del camino óptimo hasta $t$ que genera la secuencia de observaciones $Y_t=y_1,...,y_t$, terminando en el estado $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1) Inicialización:\n",
    "\n",
    "$\\phi_1(i)=b_i(y_1)\\pi_i$\n",
    "\n",
    "$\\psi_1(i)=0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Recursión:\n",
    "\n",
    "$\\phi_t(j)=b_j(y_t)\\max\\limits_{1\\leq i \\leq N} a_{ij} \\phi_{t-1}(i)$\n",
    "\n",
    "$\\psi_t(j)=\\argmax\\limits_{1 \\leq i \\leq N} \\phi_{t-1}(i) a_{ij}$\n",
    "\n",
    "Camino óptimo $S^* = s_1^*,...,s_t^*$ con $s_t^*=j$ $\\Rightarrow$ $\\psi_t(j)=s_{t-1}^*$, el estado anterior.\n",
    "\n",
    "$\\phi_t(j)$: probabilidad de ese camino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3) Backtracking:\n",
    "\n",
    "$q_T^*=\\argmax\\limits_{1 \\leq j \\leq N} \\phi_T(j)$\n",
    "\n",
    "\n",
    "\n",
    "$q_t^*=\\psi_{t+1}(q_{t+1}^*)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento de la HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T18:46:22.273662Z",
     "start_time": "2018-08-05T18:46:22.261985Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Dado $Y$, hallar $\\lambda=\\{\\{i\\},\\{a_{ij}\\},\\{b_j(y_t)\\}\\}$, con $i,j = 1,...,N$, $t = 1,...,T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo Baum-Welch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Basado en EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1) Inicialización de $\\mu_k$, $\\sigma_k$ (igual que antes, por ejemplo: K-Means), y $\\{a_{ij}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Paso E:\n",
    "\n",
    "__Recursión backward__\n",
    "\n",
    "$\\alpha_t(j)=P(y_1,...,y_t,q_t=j)$: probabilidad de la secuencia de observaciones hasta $t$ y que el estado actual sea $j$\n",
    "\n",
    "$\\alpha_t(j)=\\sum_{i=1}^N b_j(y_t)a_{ij}\\alpha_{t-1}(i)$\n",
    "\n",
    "__Recursión forward__\n",
    "\n",
    "$\\beta_t(i)=P(y_t+1,...,y_T|q_t=i)$: probabilidad de que se dé la secuencia de observaciones desde $t+1$ hasta el final, dado que el estado actual es $i$\n",
    "\n",
    "$\\beta_t(i)=\\sum_{j=1}^Nb_j(y_{t+1})a_{ij}\\beta_{t+1}(j)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\gamma_t(i)=P(q_t=i|Y)$: probabilidad de que el estado en el instante $t$ sea $i$, dada la secuencia de observaciones\n",
    "\n",
    "$\\gamma_t(i)=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum_{j=1}^N\\alpha_t(j)\\beta_t(j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\xi_t(i,j)=P(q_t=i,q_{t+1}=j|Y)$: probabilidad de estar en el estado $i$ en el instante $t$ y pasar al estado $j$, dada la secuencia de observaciones\n",
    "\n",
    "$\\xi_t(i,j)=\\frac{\\alpha_t(i)\\beta_{t+1}(j)b_j(y_{t+1})a_{ij}}{\\sum_{j=1}^N \\alpha_t(j)\\beta_t(j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3) Paso M: reestimar los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\mu_j=\\frac{\\sum_{t=1}^T \\gamma_t(j)y_t}{\\sum_{t=1}^T\\gamma_t(j)}$: media para el estado $j$: promedio ponderado de las observaciones con las probabilidades de que cada observación se dé en el estado $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\Sigma_j=\\frac{\\sum_{t=1}^T (y_t-\\mu_j)^T(y_t-\\mu_j)\\gamma_t(j)y_t}{\\sum_{t=1}^T\\gamma_t(j)}$: varianza para el estado $j$: varianza ponderada con las probabilidades de que cada observación se dé en el estado $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$a_{ij}=\\frac{\\sum_{t=1}^T \\xi_t(i,j)}{\\sum_{t=1}^T\\gamma_t(i)}$: probabilidad de transición del estado $i$ al $j$: suma de las probabilidades de pasar del estado $i$ al estado $j$ en todos los instantes, dividido por la probabilidad total de transición dsede el estado $i$ hacia otro estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4) Calcular log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "5) Repetir 2, 3, 4 hasta que el log-likelihood no cambie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T19:24:45.664857Z",
     "start_time": "2018-08-05T19:24:45.655082Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aplicación al reconocimiento de habla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T19:25:13.239342Z",
     "start_time": "2018-08-05T19:25:13.227963Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1) Set de entrenamiento: frases grabadas y sus transcripciones fonéticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Parametrización: coeficientes MFCC (12 + deltas = 39) por ventanas de 20ms, con 10ms de superposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3) HMM:\n",
    "\n",
    "* 3 estados emisores por fonema + 2 estados no emisores (inicial y final) para unirlos:\n",
    "\n",
    "![markov_fonema](markov_fonema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Por cada frase:\n",
    "![markov_frase](markov_frase.svg)\n",
    "\n",
    "\n",
    "* No hace falta segmentar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4) Modelo de lenguaje:\n",
    "\n",
    "![modelo_lenguaje](modelo_lenguaje.svg)\n",
    "\n",
    "Para las transiciones entre palabras:\n",
    "\n",
    "$P(w2|w1)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "5) Reconocimiento: Viterbi"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
